\subsection{The Reynolds Operator And Linearly Reductive Groups}

\begin{definition}[Linearly Reductive Group]
  Let $G$ be a linear algebraic group.
  We call $G$ \textbf{linearly reductive}, if and only if for any rational representation $V$ and for any $v \in V^G \setminus \{ 0 \}$ there exists an $f \in \left( V^\ast \right)^G $ such that $f(v) \neq 0$.
\end{definition}

\begin{proposition}\label{dual}
  For a linearly reductive group $G$ and a finite rational representation $V$, $V^G$ and $(V^\ast)^G$ are dual to each other with respect to the non-degenerate bilinear form $ b\colon V^\ast \times V \longrightarrow K, (f,v) \mapsto f(v)$.
\end{proposition}

\begin{proof}
  We shall first show that $\operatorname{dim}(V^\ast)^G = \operatorname{dim}V^G$.
  Let $\{v_1, \ldots , v_r \}$ be a basis of $V^G$, and expand this to a basis $\{v_1, \ldots , v_m \}$ of $V$.
  We define $\{ f_1 , \ldots , f_n \}$ to be the basis of $V^\ast$ which is dual to $\{v_1, \ldots , v_n \}$, that is we have $ f_i (v_j) = \delta_{i,j} $.
  It should be clear that $\{f_1, \ldots , f_r \} \subseteq (V^\ast)^G$.
  Now let $f \notin \operatorname{span} \{ f_1, \ldots, f_r\}$, that is we have $f = \Sigma_{i=1}^n \lambda_i f_i $, and there exists a $j > r$ such that $ \lambda_j \neq 0$.
  For this $j$, we have $v_j \notin V^G$, therefore there exists a $\sigma \in G$ such that $\sigma . v_j \neq v_j$.
  We then get \textbf{??}
  We have now shown that $(V^\ast)^G = \operatorname{span}\{f_1,\dots,f_r\}$, therefore $\operatorname{dim}(V^\ast)^G = \operatorname{dim}V^G$.
  Since $G$ is linearly reductive, we then get via our definition that $\left. b \right|_{(V^\ast)^G \times V^G}$ is non-degenerate in the first variable.
  Since $\operatorname{dim}(V^\ast)^G = \operatorname{dim}V^G$, we have that $\left. b \right|_{(V^\ast)^G \times V^G}$ is non-degenerate in both variables.
  This exactly means that the spaces $(V^\ast)^G$ and $V^G$ are dual to each other with respect to $b$.
\end{proof}

% \begin{proposition}\label{aybee}
%   Let $G$ be linearly reductive.
%   Then for every rational representation $V$ there exists a unique subrepresentation $W \subseteq V$ such that $V = V^G \oplus W$.
%   For this subrepresentation $W$ we have $(W^\ast)^G = \{0\}$.
% \end{proposition}

\begin{definition}[Reynolds Operator]
  Let $ X $ be an affine $G$-variety.
  A $ G $-invariant linear projection $R \colon K\lbrack X \rbrack \longrightarrow K\lbrack X \rbrack^G $ is called a \textbf{Reynolds operator}.
\end{definition}

\begin{definition}
  Assume that $V$ is a finite rational representation of $V$ such that there exists a unique subrepresentation of $V$ such that $V = V^G \oplus W$.
 We define $R_V \colon V \twoheadrightarrow V^G$ as the linear projection of $V$ onto $V^G$ along $W$.
\end{definition}

\begin{remark}
  $R_V$ is a $G$-invariant projection of $V$ onto $V^G$:
  If for $v \in V$ we write $v = u + w$ with $u \in V^G$ and $w \in W$, then for $\sigma \in G$ we have $\sigma.v = \sigma.u + \sigma.w = u + \sigma.w$, and therefore $R_V(\sigma.v) = u = R_V(v)$.
\end{remark}

\begin{lemma}\label{lamm}
  Assume that $G$ is a linear algebraic group with the following property:
  For every finite rational representation $V$ of $G$ there exists a unique subrepresentation $W$ of $V$ such that $V = V^G \oplus W$, and for this $W$ we have $(W^\ast)^G = \{0\}$.
  The following properties hold:
  \begin{enumerate}[(a)]
  \item If $V$ is a subrepresentation of a finite rational representation $V^\prime$ of $G$, we have $\left. R_{V^\prime} \right|_V = R_V$.
  \item If $V$ is a finite rational representation of $G$ and $R^\prime_V \colon V \longrightarrow Y$ is a $G$-invariant linear map with $V \subseteq Y$ and $ \left. R^\prime_V \right|_{V^G} = \operatorname{id}_{V^G}$, we have $R^\prime_V = R_V$, id est $R_V$ is unique with this property (\textbf{Do I need to mention that we should then view $R_V \colon V \longrightarrow V$ instead of $ \twoheadrightarrow V^G$??}).
  \item If $X$ is an affine $G$-variety and $R \colon K[X] \twoheadrightarrow K[X]^G$ is a Reynolds operator, then for every $G$-stable subspace $V$ of $K[X]$ we have $\left. R \right|_V = R_V$.
  \item If $X$ is an affine $G$-variety, $R \colon K[X] \twoheadrightarrow K[X]^G$ a Reynolds operator and $W$ is any $G$-stable subspace of $K[X]$, we have $R(W) = W^G$.
  \item If $X$ is an affine $G$-variety, the Reynolds operator is unique
  \end{enumerate}
\end{lemma}

\begin{proof}
  \hfill \break
  \underline{(a)}\\
  Let $V$ be a subrepresentation of a finite rational representation $V^\prime$ of $G$.
  We write $V = V^G \oplus W$ and $V^\prime = (V^\prime)^G \oplus W^\prime$, where $W$ and $W^\prime$ are each the unique subrepresentations of $V$ and $V^\prime$ repspectively with this property as in our assumption.
  Let $w \in W$.
  We write $w = u^\prime + w^\prime$ where $u^\prime \in (V^\prime)^G$ and $w^\prime \in W^\prime$.
  We choose a basis $\{u^\prime_i\}_{i \in [r]}$ of $(V^\prime)^G$ and $\{w^\prime_j\}_{j \in [s]}$ of $W^\prime$ and write $w = \Sigma_{i=1}^r \lambda_i u^\prime_i + \Sigma_{j=1}^s \mu_j w^\prime_j$.
  For $i \in [r]$, let us consider $\hat{u}^\prime_i \in (V^\prime)^\ast$, the dual basis element of $u^\prime_i$ with respect to the basis $\{u^\prime_i\}_{i \in [r]} \cup \{w^\prime_j\}_{j \in [s]}$ of $V^\prime$.
  Because of our assumption we have $(W^\ast)^G = \{0\}$, so we must have $\left. \hat{u}^\prime_i \right|_W = 0$, and therefore $\lambda_i = \hat{u}^\prime_i (w) = \left. \hat{u}^\prime_i \right|_W (w) = 0$.
  We retreive $u^\prime = 0$, implying $ w  = w^\prime \in W^\prime $.
  We have now shown $W \subseteq W^\prime$.
  Let $v \in V$.
  With $V^G \subseteq (V^\prime)^G$ and $R_V (v) - v \in W \subseteq W^\prime$, we retrieve $R_{V^\prime}(v) - R_V (v) = R_{V^\prime}(v - R_V(v)) = 0$.
  This concludes $\left. R_{V^\prime} \right|_V = R_V$.  \\
  \underline{(b)}\\
  Let $V$ be a finite rational representation of $G$, and let $R^\prime_V \colon V \longrightarrow Y$ be a $G$-invariant linear map where $V \subseteq Y$.
  Via our assumption, we can find a unique subrepresentation $W$ of $V$ such that $V = V^G \oplus W$.
  We obviously have $\left. R^\prime_V \right|_{V^G} = \operatorname{id}_{V^G} = \left. R_V \right|_{V^G}$.
  Let $w \in W$.
  We choose a basis $\{w_i\}_{i \in [r]}$ of $U:= \operatorname{span}(W + R^\prime_V (w))$, and we write $R^\prime_V (w) = \Sigma_{i=1}^r \lambda_i w_i$.
  Let $\{w^\prime_i\}_{i \in [r]}$ be the basis of $U^\ast$ dual to the previously mentioned basis of $U$.
  For $i \in [r]$, we have $\left. (w^\prime_i \circ R^\prime_V) \right|_W \in (W^\ast)^G = \{0\}$ via our assumption, and therefore $ \lambda_i = w^\prime_i (R^\prime_V(w)) = \left. (w^\prime_i \circ R^\prime_V) \right|_W (w) = 0$.
  This means that $R(w) = 0$.
  We now have shown $\left. R \right|_{W} = 0$.
  This concludes that $R^\prime_V = R_V$.  \\
  \underline{(c)}\\
  This follows immediately from (b):
  If $X$ is an affine $G$-variety and $R \colon K[X] \twoheadrightarrow K[X]^G$ is a Reynolds operator and $V$ is a $G$-stable subspace of $K[X]$, we have that $\left. R \right|_V \colon V \longrightarrow K[X]$ is a linear map with $V \subseteq K[X]$ and $\left. R_V \right|_{V^G} = \operatorname{id}_{V^G}$.
  Therefore we have $\left. R \right|_V = R_V$.  \\
  \underline{(d)}\\
  Let $X$ be an affine $G$-variety, $R \colon K[X] \twoheadrightarrow K[X]^G$ a Reynolds operator and $W$ is any $G$-stable subspace of $K[X]$.
  now let $w \in W$.
  Since $W$ is $G$-stable we have $V_w \subseteq W$ and with (c) therefore $R(w) = R_{V_w} (w) \in V_w^G \subseteq W^G$.
  We have therefore shown $R(W) \subseteq W^G$
  Also $\left. R \right|_{W^G} = \operatorname{id}_{W^G}$ since $W^G \subseteq K[X]^G$, concluding $R(W) = W^G$.
  \underline{(e)}\\
  This follows immediately from (c):
  Let $X$ be an affine $G$-variety and $R_1,R_2 \colon K[X] \twoheadrightarrow K[X]^G$ each a Reynolds operator.
  Now let $f \in K[X]$.
  Then $R_1(f) = R_{V_f} (f) = R_2 (f)$.
\end{proof}

\begin{remark}
  Note that in lemma \ref{lamm}(d) we just showed uniqueness without mentioning existence.
  In the following, we see that in fact there always exists a Reynolds operator for groups with the previously described properties.
\end{remark}

% \begin{remark}
%   If a Reynolds Operator exists, it is unique (?).
%   See \cite[p.39f]{DK15}: In the proof of the equivalences, in the step ``(b)$\implies$(c)'', only the existence of the Reynolds operator is needed.
%   Therefore, the existence of the Reynolds Operator already implies its uniqueness (?).
% \end{remark}

\begin{theorem}\label{equiv}
  Let $G$ be a linear algebraic group.
  The following are equivalent:
  \begin{enumerate}[(a)]
  \item $G$ is linearly reductive
  \item For every finite rational representation $V$ of $G$ there exists a unique subrepresentation $W$ with $V = V^G \oplus W$.
    For this subrepresentation $W$ we have $(W^\ast)^G = \{0\}$.
    % This subrepresentation $W$ satisfies $\left( W^\ast \right)^G = \{0\}$.
  \item For every affine $G$-variety $X$ there exists a Reynolds operator $R \colon K[X] \twoheadrightarrow K[X]^G $.
  \end{enumerate}
\end{theorem}

\begin{proof}
  \hfill \break
  \underline{(a)$\implies$(b)}\\
  Let $V$ be a finite rational representation of $G$.
  Consider the subspace $ ((V^\ast)^G)^\bot \subseteq V $.
  It is easily seen that this is a subrepresentation of $V$.
  In proposition \ref{dual}, we showed that $V^G$ and $(V^\ast)^G$ are dual to each other.
  For this reason, we have $V = V^G \oplus ((V^\ast)^G)^\bot $.
  We have shown the existence, now we shall show uniqueness.
  Let $W$ be a subrepresentation of $V$ with $V = V^G \oplus W $.
  Again, it is easily seen that $W^\bot \subseteq V^\ast$ is a subrepresentation.
  $G$ must act trivially on $W^\bot \subseteq V^\ast$:
  Let $f \in W^\bot$, and let $\sigma \in G$.
  We have $\sigma.f \in W^\bot$ and therefore $\sigma.f - f \in W^\bot$.
  Now, let $v \in V$.
  We write $v = u + w$ for (unique) $u \in V^G$ and $w \in W$ and compute:
  \begin{equation}
    \begin{aligned}
      &(\sigma.f -f)(v)&=&(\sigma.f -f)(u) + (\sigma.f -f)(w)\\
      &&=&f(\sigma^{-1}.u) - f(u) + 0\\
      &&=&f(u)-f(u) = 0
    \end{aligned}
  \end{equation}
  Which means that $\sigma.f = f$.
  Hence $G$ does act trivially on $W^\bot$.
  This means that $W^\bot \subseteq (V^\ast)^G$.
  For reasons of dimension we get $W^\bot = (V^\ast)^G$, and therefore also $W = (W^\bot)^\bot = ((V^\ast)^G)^\bot$, which concludes the claim of uniqueness.
  Finally, we notice that that $W$ and $W^\ast$ are isomorphic representations \textbf{(How clear is this??)}, which also means that $(W^\ast)^G$ and $W^G$ are isomorphic.
  Since we have $W^G = \{0\}$, we therefore must also have $(W^\ast)^G = \{0\}$.\\
  \underline{(b)$\implies$(c)}\\
  Let $X$ be an affine $G$-variety.
  Let $f \in K[X]$.
  We define the map $R \colon K[X] \longrightarrow K[X]^G $, $ f \mapsto R_{V_f}(f)$.
  For $f \in K[X]$ we denote by $W_f$ the unique subrepresentation of $V_f$ such that $V_f = V_f^G \oplus W_f$ as in (b).
  This map is linear:
  Let $f,g \in K[X]$ and $\lambda \in K$.
  We notice that $V_f,V_g,V_{\lambda f + g} \subseteq V_f + V_g$, which together with lemma \ref{lamm}(a) gives us $R(\lambda f +g) = R_{V_{\lambda f +g}}(\lambda f+g) = R_{V_f +V_g}(\lambda f+g) = \lambda R_{V_f + V_g} (f) + R_{V_f + V_g}(g) = \lambda R_{V_f} (f) + R_{V_g}(g) = \lambda R(f) + R(g)$.
  The map $R$ is also a projection onto $K[X]^G$, since for each $f \in K[X]$ we have $V_f^G \subseteq K[X]^G$.
  $R$ is also $G$-invariant, since for all $f \in K[X]$ $R_{V_f}$ is $G$-invariant and for all $\sigma \in G$ we have $V_f = V_{\sigma.f}$.
  This concludes that $R$ is a Reynolds operator, which shows (c).  \\
  \underline{(c)$\implies$(a)}  \\
  Let $V$ be a finite rational representation of $G$ and let $v \in V^G \setminus \{0\}$.
  We choose a basis $\{v_i\}_{i\in [r]}$ of $V$ with $v_1 = v$.
  Let $\hat{v} \in V^\ast$ be the dual basis vector of $v$ with respect the afore mentioned basis.
  Now we define $p_v \colon K[V^\ast] \twoheadrightarrow K$, $f \mapsto f(\tilde{v})$.
  Consider the isomorphism $\Phi \colon V \longrightarrow (V^\ast)^\ast$, $w \mapsto (\phi \mapsto \phi (w))$.
  We have $(V^\ast)^\ast \subseteq K[V^\ast]$.
  Since $V^\ast$ is a finite rational representation and since via our assumption (c) we have a Reynolds operator $R \colon K[V^\ast] \twoheadrightarrow K[V^\ast]^G$, we can define $ \psi_v := p_v \circ R \circ \Phi \colon V \longrightarrow K$.
  Since each map is linear, we have $\psi_v \in V^\ast$.
  After we notice that since $v \in V^G$ we have $\Phi (v) \in K[V^\ast]^G$, we can calculate $\psi_v (v) = p_v (\Psi(v)) = \Phi (v) (\tilde{v}) = \tilde{v} (v) = 1 \neq 0$.
  This concludes that $G$ is linearly reductive, showing (a).
\end{proof}

\subsection{Hilbert's Finiteness Theorem}

\begin{proposition}
  See \cite[p.41 Corollary 2.2.7]{DK15}\\
  Let $G$ be a linearly reductive group, and let $ R \colon K[X] \twoheadrightarrow K[X]^G $ be the Reynolds operator for an affine $G$-variety $X$.
  If $f \in K[X]^G$ and $g \in K[X]$ we have $R(fg) = fR(g)$, id est the Reynolds operator is a \textit{$K[X]^G$-module homomorphism}.
\end{proposition}

\begin{proof}
  Let $f \in K[X]^G$ and $g \in K[X]$.
  We can decompose $V_g = V_g^G \oplus W_g$ uniquely, where $W_g$ is a subrepresentation of $V_g$.
  We have $(fW)^G = {0}$:
  Let $h \in (fW)^G$, say $h = fw$ where $w \in W$.
\end{proof}

% \begin{lemma}\label{dl}
%   If $G$ is linearly reductive and $X$ is a $G$-variety, we have:
%   \begin{enumerate}[(a)]
%   \item For all $G$-stable subspaces $W \subseteq K[X]$ we have $R(W) = W^G$
%   \item For all $f \in K[X]^G$ and for all $g \in K[X]$ we have $R(fg) = fR(g)$
%   \end{enumerate}
% \end{lemma}

\begin{theorem}[Hilbert's Finiteness Theorem]
  If $G$ is linearly reductive and $V$ is a finite-dimensional rational $G$-representation, the invariant ring $K[V]^G$ is finitely generated.
\end{theorem}

\begin{proof}
  Let $I_{>0}$ denote the ideal generated by all non-constant invariants in $K[V]$.
  Since $K[V]$ is noetherian, there exist finitely many $\{f_i\}_{i \in [r]} \subseteq K[V]$ such that $ \left( \{f_i\}_{i \in [r]} \right) = I_{i>0} $.
  These must be non-constant invariants (the zero polynomial will always be omitted).
  Claim: $K[\{f_i\}_{i \in [r]}] = K[V]^G$.
  The inclusion ``$\subseteq$'' is clear.
  To show is $\supseteq$''.
  This is equivalent to showing that for all $d \in \mathbb{N}$ we have $K[V]^G_{<d} \subseteq K[\{f_i\}_{i \in [r]}] $.
  We will show our claim via induciton over the degree $d$.
  For $g \in K[V]^G_{<1} = K$ we are already done since $K \subseteq K[\{f_i\}_{i \in [r]}]$.
  Now assume that for $d \in \mathbb{N}$ we have $K[V]^G_{<d} \subseteq K[\{f_i\}_{i \in [r]}]$.
  Let $g \in K[V]^G_{< d+1}$.
  By construction, $g \in I_{>0}$, therefore there exist $\{g_i\}_{i \in [r]} \subseteq K[V]$ such that $g = \Sigma_{i=1}^r g_i f_i$.
  Since the $f_i$ are of non-constant and $\operatorname{deg} g < d+1$, we must have $ \operatorname{deg} g_i < d $.
  We now make use of the Reynolds Operator:
  \begin{equation}
      g = R(g)
      =  R \left( \sum_{i=1}^r g_i f_i \right)
      = \sum_{i=1}^r R( g_i) f_i
  \end{equation}
  Since $R$ maps $K[V]_{<d}$ to $K[V]^G_{<d}$, we have $R(g_i) \in K[V]^G_{<d} \subseteq K[\{f_i\}_{i \in [r]}]$ by our induction hypothesis.
  This finally implies $ g \in K[\{f_i\}_{i \in [r]}]$, which concludes our proof:
  We have $K[V]^G = K[\{f_i\}_{i \in [r]}]$ which means that $K[V]^G$ is finitely generated, which was to show.
\end{proof}

\begin{lemma}
  See \cite[2.2.8]{DK15}
\end{lemma}

\begin{proof}
  
\end{proof}

\begin{lemma}
  See \cite[2.2.9]{DK15}
\end{lemma}

\begin{proof}
  
\end{proof}

\begin{theorem}[Hilbert's Finiteness Theorem For Affine Varieties]
  If $G$ is a linearly reductive group and $X$ is an affine $G$-variety, $K[X]^G$ is finitely generated.
\end{theorem}

\begin{proof}
  
\end{proof}

\subsection{The Reynolds Operator Of A Linear Algebraic Group}

% \begin{definition}[linearly reductive]
%   A group $G$ is called \textbf{linearly reductive} iff there exists a Reynolds operator $ R_G \colon K\lbrack G \rbrack \longrightarrow K\lbrack G \rbrack^G = K $ for the regular action $ G \times G \longrightarrow G $ by left multiplication.
% \end{definition}

% \begin{remark}
%   We could have also defined linear reductive groups as such, for which every regular action has a Reynolds Operator.
%   We will prove in proposition \ref{ro} that this is in fact equivalent.
% \end{remark} 

In theorem \ref{equiv} we have learned about three characterizations of linearly reductive groups, but for a given linear algebraic group, it is still hard to concretely show that it is linearly reductive.
We will soon learn about a fourth way to characterize linearly reductive groups, which will motivate the main theme of my work:  Cayley's $\Omega$-process.

\begin{definition}
  Define the multiplication on $ K \left\lbrack G \right\rbrack^\ast $, denoted by $\ast$, as follows:  For $\alpha, \beta \in K \left\lbrack G \right\rbrack^\ast$:  
  \begin{equation}
    \alpha \ast \beta := \left( \alpha \otimes \beta \right) \circ m^\ast
  \end{equation}
  More slowly: For $f \in K \left\lbrack G \right\rbrack$ we get $m^\ast \left( f \right) = \Sigma_i g_i \otimes h_i$ (with $g_i , h_i \in K \left\lbrack G \right\rbrack$), therefore the Kronecker-product gives us
  \begin{equation}
    \left( \alpha \ast \beta \right) \left( f \right) = \Sigma_i \alpha \left( g_i \right) \otimes \beta \left( h_i \right) = \Sigma_i \alpha \left( g_i \right) \beta \left( h_i \right)
  \end{equation}
  As usual, we identify $K \otimes K$ with $K$ canonically.  
\end{definition}
% % BEGIN COMPLETE UTTER BULLSHIT PLEASE DON'T READ
%
% Let us look at this more concretely.
% Let $f \in K \left\lbrack G \right\rbrack$, $\alpha,\beta \in K \left\lbrack G \right\rbrack^\ast$.
% Write $f= \Sigma_{E \in \mathbb{N}^{n \times n}} \quad \lambda_E \cdot X^E \cdot \operatorname{det}\left( X \right)^{-e}$.
% Then we can compute:
% \begin{equation}
%   m^\ast \left( f \right) = \sum_{E \in \mathbb{N}^{n \times n}} \lambda_E \cdot X^E \cdot \operatorname{det}\left( X \right)^{-e} \otimes X^E \cdot \operatorname{det}\left( X \right)^{-e}
% \end{equation}
% Note that $\operatorname{det}$ is multiplicative.
% We then conclude:
% \begin{equation}
%   \left( \alpha \ast \beta \right) \left( f \right) = \sum_{E \in \mathbb{N}^{n \times n} } \lambda_E \cdot \alpha \left( X^E \cdot \operatorname{det}\left( X \right)^{-e} \right) \cdot \beta \left( X^E \cdot \operatorname{det}\left( X \right)^{-e} \right)
% \end{equation}
% We here see that $\alpha \ast \beta \in K \left\lbrack G \right\rbrack^\ast$.
%
% % END COMPLETE UTTER BULLSHIT ARIGATOU GOZAIMASU

\textbf{Example:} TODO

\begin{proposition}
The multiplication $\ast$ makes $K \left\lbrack G \right\rbrack^\ast$ into an associative algebra with the neutral element $ \epsilon := \epsilon_e$ (Note: $\epsilon_\sigma \left( f \right) = f \left( \sigma \right)$).
\end{proposition}

\begin{proof}
  First, a small observation:
  \begin{equation}
    \left(m^\ast \otimes \operatorname{id} \right) \circ m^\ast = \left( \operatorname{id} \otimes m^\ast \right) \circ m^\ast
  \end{equation}
  This is true because $m$ (and $ \otimes $) is associative.
  Then, for $\delta, \gamma, \varphi \in K \left\lbrack G \right\rbrack^\ast$:
  \begin{equation}
    \begin{aligned}
      \left( \delta \ast \gamma \right) \ast \varphi
      = \left( \left( \left( \delta \otimes \gamma \right) \circ m^\ast \right) \otimes \varphi \right) \circ m^\ast
      = \left( (\delta \otimes \gamma) \otimes \varphi \right) \circ \left( m^\ast \otimes \operatorname{id} \right) \circ m^\ast \\
      = \left( \delta \otimes (\gamma \otimes \varphi) \right) \circ \left( \operatorname{id} \otimes m^\ast \right) \circ m^\ast
      = \left( \delta \otimes \left( \left( \gamma \otimes \varphi \right) \circ m^\ast \right) \right) \circ m^\ast
      = \delta \ast \left( \gamma \ast \varphi \right)
    \end{aligned}
  \end{equation}
  showing the associativity.
  % The second and third equations follow from associativity and are easily checked.  %(rewrite as described in the beginning of chapter \ref{pw})
  It should be clear that $\epsilon$ is the neutral element.
  This concludes that $K \left\lbrack G \right\rbrack^\ast$ is an associative algebra.
\end{proof}

Now we can formally define $K [G]^\ast$-actions.

\begin{definition}\label{da}
  Let $G$ act regularly on a vector-space $V$ via $\mu$, from which we retrieve $\mu^\prime$ as described in definition \ref{rr}.  $K[G]^\ast$ then acts on $V$ as follows:
  \begin{equation}
    \delta \cdot v := \left(\left( \delta \otimes \operatorname{id} \right) \circ \mu^\prime \right) \left(v\right)
  \end{equation}
\end{definition}

\begin{remark}
  If we look at definition \ref{rr}, we can see that this newly defined $K[G]^\ast$-action is an extension of the given $G$-action in the following way:
  The subgroup $\left\{\, \epsilon_\sigma \mid \sigma \in G \,\right\}$ of $K[G]^\ast$ is isomorphic to $G$, and its induced action coincides with the given action:
  For $\sigma \in G$ and for $v \in V$ we have:
  \begin{equation}
    \sigma . v = \epsilon_\sigma \cdot v
  \end{equation}
\end{remark}

\begin{remark}
  The subalgebra
  \begin{equation}
    \left\{\, \delta \in K[G]^\ast \mid \forall f,g \in K[G] : \delta (fg) = \delta (f) g(e) + f(e)\delta (g) \,\right\}
  \end{equation}
  is called the \textbf{Lie algebra}.
\end{remark}

\begin{proposition}\label{ro}
  Let $G$ be linearly reductive, and let $G$ act regularly on an affine variety $X$, which induces a rational $G$-action on $K[X]$ as described in definition \ref{funrep}.
  Then, the following the map
  \begin{align}
    R \colon K[X] \longrightarrow K[X]^G && f \mapsto R_G \cdot f
  \end{align}
  defines a Reynolds operator.
\end{proposition}

\begin{proof}
  As per our construction from definition \ref{da}, the linearity of this map should be clear.
  Let us now check that $R$ does map polynomials to invariant polynomials.
  For this, let $f \in K[X]$, $\sigma \in G$ and $x \in X$.
  Write $\mu^\prime (f) = \Sigma_i p_i \otimes g_i \in K[G] \otimes K[X] $.
  Now we compute:
  \begin{equation}
    \begin{aligned}
      &\sigma . \left( R_G \cdot f \right) (x)
      &=& \left( R_G \otimes \operatorname{id} \right) \left( \mu^\prime(f) \right) \left( \sigma^{-1}.x \right) \\
      &&=& \Sigma_i R_G \left( p_i \right)  g_i \left( \sigma^{-1} . x \right) \\
      &&=& \Sigma_i R_G (p_i) \cdot (\sigma . g_i) (x)\\
      &&=& \Sigma_i R_G (\sigma \dot{\phantom{.}} p_i) \cdot (\sigma.g_i) (x)\\
      &&=&(R_G \otimes \operatorname{id}) \left( \Sigma_i \sigma \dot{\phantom{.}} p_i \otimes \sigma.g_i \right) (x) \\ 
      &&=& (R_G \otimes \operatorname{id}) (\mu^\prime (f)) (x)
      &=& (R_G \cdot f) (x)
    \end{aligned}
  \end{equation}
  The second-to-last equation can be seen as follows:
  For all $\tau \in G$ we have
  \begin{equation}
    \begin{aligned}
      & \Sigma_i \sigma \dot{\phantom{.}} p_i (\tau) \sigma . g_i
      &=& \Sigma_i  p_i (\tau \sigma^{-1}) \sigma . g_i\\
      &&=& \tau \sigma^{-1} . (\sigma . f) \\
      &&=& \tau . f \\
      &&=& \Sigma_i p_i (\tau) g_i
    \end{aligned}
  \end{equation}
  making use of proposition \ref{rara}.
  We have now shown that $R_G \cdot f \in K[V]^G$.
  If $f \in K[V]^G$, we have $\mu^\prime (f) = 1 \otimes f$, therefore 
  
  not done yet pls finish
\end{proof}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "roughdraft"
%%% End:
